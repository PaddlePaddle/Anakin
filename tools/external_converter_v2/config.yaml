#---------------------------------------------------------------
##  configuration file of external model convert to anakin
##---------------------------------------------------------------
#
##---------------------------------------------------------------
##  Default configuration options
##  @Param Framework:
##         The model you need to parser. e.g.:
##         CAFFE, PADDLE, [ TENSORFLOW, MXNET, TORCH ]  ...
##         Now we support CAFFE, PADDLE
##         next we will support MXNET, TENSORFLOW ...
##  @Param SavePath:
##         The path where converted model will be saved
##  @Param ResultName
##         Name in anakin of parsed model.
##  @Param LaunchBoard: (OFF/ON)
##         Whether to launch anakin graph dash board ( you must set the right ip and port at the same time if LaunchBoard is ON)
##  @Param ip
##         Anakin graph dash board server ip ( local boardcast ip or real ip)
##  @Param port
##         Anakin graph dash board server port ( you need to set os open the port )
##  @Param OptimizedGraph:
##             |- enable (OFF/ON) : Whether to visualize the necessary compute and optimization analysis of graph
##             `- path: This place the optimized anakin model path generated by anakin framework's api graph::save
##  @Param LogToPath
##         Path the log saved.
##  @Param WithColor: (OFF/ON)
##         Wether to usecolorful log
##
##  @Param TARGET::CAFFE ...
##         You only need to fill in the framework config
##         you need to convert
##  @Param ProtoPaths:
##         Protobuf define files, maybe a list.
##  @Param PrototxtPath:
##         Json define prototxt file path  of you model
##  @Param ModelPath:
##         Path of you binary model.
##
##--------------------------------------------------------------
#
OPTIONS:
    Framework: CAFFE
    SavePath: ./output
    ResultName: googlenet
    Config:
        LaunchBoard: ON
        Server:
            ip: 0.0.0.0
            port: 8888
        OptimizedGraph:
            enable: OFF
            path: /path/to/anakin_optimized/googlenet.anakin.bin.saved
    LOGGER:
        LogToPath: ./log/
        WithColor: ON 

TARGET:
    CAFFE:
        # path to proto files
        ProtoPaths:
            - /path/to/caffe.proto
        PrototxtPath: /path/to/your/googlenet.prototxt
        ModelPath: /path/to/your/googlenet.caffemodel
        Remark:  # Generally no need to modify.

    FLUID:
        # path of fluid inference model
        Debug: NULL                            # Generally no need to modify.
        ModelPath: /path/to/your/model/        # The upper path of a fluid inference model.
        NetType:                               # Generally no need to modify.

    LEGO:
        # path to proto files
        ProtoPath:
        PrototxtPath:
        ModelPath:

    TENSORFLOW:
        ModelPath: /path/to/your/model/
        OutPuts:

    ONNX:
        ModelPath:
